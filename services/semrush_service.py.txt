import requests
import pandas as pd
from io import StringIO
import logging
import time
from typing import List, Dict, Any, Tuple, Optional

from config import Config

logger = logging.getLogger(__name__)

class SEMrushService:
    """Service for interacting with the SEMrush API"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or Config.SEMRUSH_API_KEY
        self.base_url = Config.SEMRUSH_API_URL
        
        if not self.api_key:
            logger.warning("No SEMrush API key provided. API calls will fail.")
    
    def _make_request(self, endpoint: str, params: Dict[str, Any]) -> pd.DataFrame:
        """Make a request to the SEMrush API and return the response as a DataFrame"""
        # Add API key to params
        params['key'] = self.api_key
        
        # Make the request
        try:
            response = requests.get(f"{self.base_url}/{endpoint}", params=params)
            response.raise_for_status()
            
            # SEMrush returns CSV data by default
            csv_data = StringIO(response.text)
            return pd.read_csv(csv_data)
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Error making request to SEMrush API: {e}")
            # Check for rate limiting
            if response.status_code == 429:
                logger.warning("Rate limit exceeded. Waiting before retrying.")
                time.sleep(60)  # Wait a minute before retrying
                return self._make_request(endpoint, params)
            
            # Return empty DataFrame on error
            return pd.DataFrame()
    
    def get_domain_overview(self, domain: str, database: str = 'us') -> Dict[str, Any]:
        """Get domain overview including authority score, traffic, and backlinks"""
        params = {
            'type': 'domain_ranks',
            'domain': domain,
            'database': database,
            'export_columns': 'Dn,Rk,Or,Ot,Oc,Ad,At,Ac,Dl,Fb,Tw,Vk,Rd,Lk,Mv,Cp'
        }
        
        df = self._make_request('analytics/v1', params)
        
        if df.empty:
            return {}
        
        # Convert DataFrame to dictionary
        data = df.iloc[0].to_dict()
        
        # Return standardized format
        return {
            'domain': domain,
            'authority_score': data.get('Rk', 0),  # SEMrush Rank
            'organic_traffic': data.get('Ot', 0),  # Organic Traffic
            'backlink_count': data.get('Dl', 0),   # Backlink count
            'keyword_count': data.get('Or', 0),    # Organic keywords
            'semrush_data': data                   # All raw data
        }
    
    def get_keywords_overview(self, domain: str, database: str = 'us', limit: int = 100) -> List[Dict[str, Any]]:
        """Get keywords for a domain with search volume and difficulty"""
        params = {
            'type': 'domain_organic',
            'domain': domain,
            'database': database,
            'display_limit': limit,
            'export_columns': 'Ph,Po,Nq,Cp,Co,Kd,Tr,Tc'
        }
        
        df = self._make_request('analytics/v1', params)
        
        if df.empty:
            return []
        
        # Convert DataFrame to list of dictionaries
        keywords = []
        for _, row in df.iterrows():
            keywords.append({
                'keyword': row.get('Ph', ''),           # Phrase
                'position': row.get('Po', 0),           # Position
                'search_volume': row.get('Nq', 0),      # Search volume
                'difficulty': row.get('Kd', 0),         # Keyword Difficulty
                'cpc': row.get('Cp', 0),                # Cost Per Click
                'competition': row.get('Co', 0),        # Competition
                'traffic': row.get('Tr', 0)             # Traffic
            })
        
        return keywords
    
    def get_keyword_magic_data(self, keyword: str, database: str = 'us', limit: int = 100) -> List[Dict[str, Any]]:
        """Get keyword suggestions and data from Keyword Magic Tool"""
        params = {
            'type': 'phrase_fullsearch',
            'phrase': keyword,
            'database': database,
            'display_limit': limit,
            'export_columns': 'Ph,Nq,Cp,Co,Nr,Td,In,Rr,Fk'
        }
        
        df = self._make_request('keywords_analytics/v1', params)
        
        if df.empty:
            return []
        
        # Convert DataFrame to list of dictionaries
        keywords = []
        for _, row in df.iterrows():
            keywords.append({
                'keyword': row.get('Ph', ''),           # Phrase
                'search_volume': row.get('Nq', 0),      # Search volume
                'difficulty': row.get('Td', 0),         # Trend difficulty
                'cpc': row.get('Cp', 0),                # Cost Per Click
                'competition': row.get('Co', 0),        # Competition
                'intent': row.get('In', ''),            # Intent
                'results_count': row.get('Nr', 0)       # Number of results
            })
        
        return keywords
    
    def get_backlinks(self, domain: str, limit: int = 100) -> List[Dict[str, Any]]:
        """Get backlinks for a domain"""
        params = {
            'type': 'backlinks',
            'target': domain,
            'display_limit': limit,
            'export_columns': 'source_url,target_url,source_title,source_ip,source_size,external,page_score,domain_score,source_country,first_seen,last_seen'
        }
        
        df = self._make_request('backlinks/v1', params)
        
        if df.empty:
            return []
        
        # Convert DataFrame to list of dictionaries
        backlinks = []
        for _, row in df.iterrows():
            backlinks.append({
                'source_url': row.get('source_url', ''),
                'source_domain': self._extract_domain(row.get('source_url', '')),
                'page_score': row.get('page_score', 0),
                'domain_score': row.get('domain_score', 0),
                'first_seen': row.get('first_seen', ''),
                'last_seen': row.get('last_seen', '')
            })
        
        return backlinks
    
    def _extract_domain(self, url: str) -> str:
        """Extract domain from URL"""
        from urllib.parse import urlparse
        try:
            parsed_url = urlparse(url)
            return parsed_url.netloc
        except:
            return url